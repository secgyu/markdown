# 1. 시스템 개요 및 요구사항 분석
## 1.1 시스템 목표
- 휠체어 사용자를 감지하여 화장실 문의 자동 개폐를 제어
- 내부 닫힘 버튼을 통해 사용자가 문을 닫을 수 있다.
- 내부 열림 버튼을 통해 사용자가 문을 열 수 있다.
- 외부에서 다른 휠체어 사용자가 접근해도 내부에 사람이 있을 때는 문이 열리지 않는다.
- 인터넷 없이 오프라인 환경에서 동작한다.

## 1.2 요구사항
- **하드웨어**
    - 라즈베리파이
    - 30FPS 지원 카메라
    - 문 제어용 릴레이 모듈
    - 닫힘 및 열림 버튼
- **소프트웨어** 
    - OpenCV 라이브러리
    - 파이썬
- **데스크톱 환경**
    - GPU를 갖춘 데스크톱 컴퓨터
    - TensorFlow 및 필요한 라이브러리 설치(모델 학습용)

# 2. 하드웨어 구성
## 2.1 라즈베리 설정
- **모델 선택** : 라즈베리파이 5모델
- **전원 공급** : 안정적 공급을 위해 5V 3A 이상 어뎁터 사용
- **냉각** : 방열판과 팬을 설치하여 발열 관리

## 2.2 카메라 설치
- **카메라 선택** : 라즈베리파이 카메라 모듈 V2 or USB 웹캠
- **설치 위치** : 화장실 외부 입구 상단에 설치하여 휠체어 사용자의 접근 감지

## 2.3 문 제어 장치
- **릴레이 모듈** : 라즈베리파이의 GPIO 핀을 통해 문 계패 제어
- **전기적 연결** : 릴레이 모듈을 통해 문 개폐 장치와 라즈베리파이 연결

## 2.4 버튼 설치
- **닫힘 버튼** : 화장실 내부에 설치하여 사용자가 문을 닫을 수 있도록 함
- **열림 버튼** : 화장실 내부에 설치하여 사용자가 문을 열 수 있도록 함
- **GPIO 연결** : 버튼을 라즈베리파이의 GPIO 핀에 연결

# 3. 데이터 수집 및 준비
## 3.1 휠체어 이미지 수집
- **이미지 다양성 확보** : AI Hub등 여러 사이트에서 다양한 각도, 거리, 조명 조건에서 휠체어 이미지 수집
- **비휠체어 이미지 수집** : 일반 사람이나 배경 이미지를 함께 수집하여 모델 정확도 향상

## 3.2 데이터 주석 작업
- **도구 사용** : Label Img등의 주석 도구를 사용하여 이미지에 바운딩 박스와 라벨 지정

```python
$ pip install labelImg
$ labelImg
```

- **클래스 정의** : '휠체어'와 '배경' 또는 '비휠체어'로 클래스 분류

## 데이터 증강 
- **증강 기법** : 회전, 확대/축소, 밝기 조절 등을 통해 데이터셋 확대
- **목적** : 모델의 일반화 성능 향상 및 과적합 방지

# 4. 모델 학습 및 최적화
## 4.1 모델 선택
- **SSD MobileNet-V2** : 경량화와 실시간 추론을 위해 적합한 모델 선택

## 4.2 학습 환경 구축
- **필요한 라이브러리 설치**
```
pip install tensorflow opencv-python
```
- **GPU 환경 구성**
    - CUDA 및 cuDNN 설치하여 GPU 가속 활용

## 4.3 모델 학습
- **학습 스크립트 작성**
    - TensorFlow Object Detection API 또는 Keras 활용
- **하이퍼파라미터 설정** 
    - 학습률, 배치크기, 에폭 수 등 최적화
- **손실 함수 및 옵티마이저 선택**
    - 교차 엔트로피 손실 함수와 Adam 옵티마이저 사용
- **모델 저장**:
    - 학습 완료 후 모델 가중치와 구조 저장

## 4.4 모델 최적화 (TensorFlow 모델을 OpenCV에서 사용 가능하도록 변환)
- **Frozen Graph 생성
```bash
$ python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ssd_mobilenet_v2.config --trained_checkpoint_dir training/ --output_directory exported_model/

```
- **OpenCV에서 사용할 수 있는형태로 변환**
    - ``.pb`` 파일과 텍스트 그래프 파일 생성
- **그래프 텍스트 파일 생성**
```bash
$ python ~/opencv/scripts/ctools/tf_text_graph_ssd.py --input frozen_inference_graph.pb --output graph.pbtxt --config ssd_mobilenet_v2.config --pipeline_config ssd_mobilenet_v2.config
```


# 5. 라즈베리파이에서 모델 배포
## 5.1 라이브러리 설치
- **OpenCV 설치**
```
$ sudo apt-get update
$ sudo apt-get install python3-opencv
```
- **OpenCV 버전 확인**
```python
import cv2
print(cv2.__version__)
```
- 버전이 낮은 경우 빌드가 힘들어 4.x버전 사용

- 필요한 라이브러리 설치
```python
$ pip3 install numpy
```

## 5.2모델 파일 복사
- **모델 파일 전송**
```bash
# 데스크톱에서 라즈베리파이로 모델 파일 전송
$ scp frozen_inference_graph.pb pi@라즈베리파이_IP주소:/home/pi/
$ scp graph.pbtxt pi@라즈베리파이_IP주소:/home/pi/
```

# 6.실시간 휠체어 감지 구현
## 6.1 OpenCV DNN 모듈을 사용한 추론 코드 작성
### 6.1.1 사전준비
- **모델 파일 준비** : 데스크톱에서 TensorFlow를 이용해 학습한 frozen_inference_graph.pb와 모델 구조를 나타내는 graph.pbtxt 파일을 라즈베리파이에 복사한다.
- **클래스 ID확인** :학습 시 지정한 휠체어 클래스의 ID를 확인하여 코드에서 사용할 수 있도록 합니다.
### 6.1.2 OpenCV DNN 모듈로 모델 로드
- **네트워크 로드**: OpenCV의 readNetFromTensorflow 함수를 사용하여 모델 파일과 그래프 파일을 로드합니다
- **모델 최적화** : 필요한 경우 모델을 양자화하거나 최적화하여 라즈베리파이에서의 추론 속도를 향상시킵니다.

### 6.1.3 카메라 초기화 및 프레임 캡처
- **카메라 설정** : 라즈베리파이 카메라 모듈 또는 USB 웹캠을 사용하여 카메라를 초기화합니다
- **프레임 캡처 루프 시작**: 무한 루프를 통해 지속적으로 프레임을 캡처하고 처리할 준비를 합니다.

### 6.1.4 프레임 전처리
- **이미지 리사이즈** : 프레임을 네트워크 입력 크기에 맞게 리사이즈합니다(예: 300x300).
- **블롭(blob)생성** : OpenCV의 blobFromImage 함수를 사용하여 프레임을 전처리합니다.
    - 색상 채널 교환(SwapRB), 평균 값 보정, 스케일링 등을 수행합니다

### 6.1.5 딥러닝 모델을 통한 추론
- **네트워크 입력 설정** : 전처리된 블롭을 네트워크의 입력으로 설정합니다.
- **추론 실행** : 네트워크의 forward 함수를 호출하여 추론을 수행합니다.
- **결과 획득** : 추론 결과로부터 탐지된 객체들의 클래스 ID, 신뢰도, 바운딩 박스 좌표 등을 얻습니다.

### 6.1.6 결과 해석 및 휠체어 감지 판단
- **신뢰도 필터링** : 각 탐지된 객체에 대해 신뢰도가 임계값(예: 50%) 이상인지 확인합니다.
- **클래스 ID 확인** : 객체의 클래스 ID가 휠체어 클래스 ID와 일치하는지 확인합니다.
- **휠체어 감지 처리**:
    - 감지된 휠체어의 바운딩 박스 좌표를 저장합니다.
    - 휠체어가 감지되었다는 플래그를 설정하여 이후 로직에서 활용합니다.

### 6.1.7 객체 추적기 초기화 및 업데이트
- **객체 추적기 선택** : OpenCV에서 제공하는 KCF 또는 CSRT 등의 추적 알고리즘을 선택합니다.
- **추적기 초기화** : 휠체어가 최초로 감지되면 추적기를 초기화하고, 바운딩 박스를 설정합니다.
- **추적 업데이트** : 각 프레임마다 추적기를 업데이트하여 휠체어의 위치를 추적합니다.
- **추적 실패 처리** : 추적이 실패한 경우 추적기를 재설정하거나 추적을 종료하고 새로운 객체 감지를 대기합니다.

### 6.1.8 이동 방향 감지
- **위치 정보 저장** : 추적된 객체의 현재 위치를 저장합니다.
- **이동 계산** : 이전 위치와 현재 위치를 비교하여 이동 방향과 거리를 계산합니다.
- **입장/퇴장 판단**:
    - 이동 거리가 임계값을 넘을 경우 입장 또는 퇴장으로 판단합니다
    - 예를 들어, 객체가 오른쪽에서 왼쪽으로 이동하면 입장, 반대 방향이면 퇴장으로 설정합니다.
- **상태 변수 업데이트** : 입장 또는 퇴장 이벤트 발생 시 관련 상태 변수를 업데이트합니다.

### 6.1.9 시각화 및 디버깅 (선택 사항)
- **바운딩 박스 그리기** : 프레임에 감지된 휠체어의 바운딩 박스를 그려서 시각적으로 확인합니다.
- **상태 정보 표시** : 입장 중, 퇴장 중 등의 상태를 프레임에 표시하여 디버깅에 활용합니다.
- **프레임 출력** : OpenCV의 imshow 함수를 사용하여 처리된 프레임을 화면에 출력합니다.

## 6.2 문 제어 로직 추가
### 6.2.1 GPIO 설정 및 초기화
- **GPIO 모드 설정** : BCM 모드로 설정하여 핀 번호를 지정합니다.
- **릴레이 핀 설정** : 문을 제어하는 릴레이 핀을 출력 모드로 설정합니다.
- **버튼 핀 설정** : 닫힘 및 열림 버튼 핀을 입력 모드로 설정하고 풀업 저항을 활성화합니다.
- **이벤트 감지 설정** : 튼 핀에 이벤트 감지를 설정하여 버튼이 눌렸을 때 콜백 함수를 호출하도록 합니다.

### 6.2.2 문 제어 함수 정의
- open_door 함수:
    - 릴레이를 제어하여 문을 엽니다.
    - 필요에 따라 릴레이 신호를 일정 시간 유지하거나 토글합니다.
- close_door 함수:
    - 릴레이를 제어하여 문을 닫습니다.
    - 안전을 위해 릴레이 신호를 일정 시간 유지합니다.
- 버튼 콜백 함수:
    - 닫힘 버튼이 눌렸을 때 close_door 함수를 호출하고 점유 상태를 True로 설정합니다.
    - 열림 버튼이 눌렸을 때 open_door 함수를 호출하고 점유 상태를 False로 설정합니다.

### 6.2.3 문 제어 로직 적용
- 휠체어 감지 시 문 열림:
    - 화장실이 비어 있고(is_occupied == False), 휠체어가 감지되면 문을 엽니다.
    - open_door 함수를 호출하여 문을 엽니다.
- 입장 이벤트 발생 시 문 닫힘:
    - 휠체어가 입장 중으로 판단되면 문을 닫고 점유 상태를 True로 설정합니다.
    - close_door 함수를 호출하여 문을 닫습니다.
- 퇴장 이벤트 발생 시 문 열림:
    - 휠체어가 퇴장 중으로 판단되면 문을 열고 점유 상태를 False로 설정합니다.
    - open_door 함수를 호출하여 문을 엽니다.
- 점유 상태에 따른 동작:
    - 화장실이 점유된 상태에서는 외부에서 휠체어가 감지되어도 문이 자동으로 열리지 않습니다.
    - 내부 버튼을 통해서만 문을 열거나 닫을 수 있습니다.

### 6.2.4 상태 관리 및 예외 처리
- 상태 변수 관리:
    - is_occupied: 화장실의 점유 상태를 나타내는 변수로, 입장/퇴장 이벤트 및 버튼 입력에 따라 업데이트됩니다.
    - tracking: 객체 추적 중인지 여부를 나타내는 변수로, 추적기의 상태에 따라 업데이트됩니다.
- 예외 처리:
    - 프로그램 실행 중 발생할 수 있는 예외 상황에 대비하여 예외 처리를 구현합니다.
    - 카메라 오류, GPIO 오류 등 발생 시 적절한 에러 메시지를 출력하고 리소스를 정리합니다.
- 리소스 정리:
    - 프로그램 종료 시 카메라와 GPIO 설정을 안전하게 종료하고 초기화합니다.

## 6.3 전체 흐름 요약
1. 초기화 단계:
    - 모델과 그래프 파일을 로드하여 딥러닝 네트워크를 초기화합니다.
    - 카메라와 GPIO를 설정하고, 필요한 변수들을 초기화합니다.
2. 실시간 프레임 처리 루프:
    - 프레임을 캡처하고 전처리하여 네트워크에 입력합니다.
    - 딥러닝 모델을 통해 휠체어 감지를 수행합니다.
    - 감지 결과에 따라 객체 추적을 시작하거나 업데이트합니다.
    - 이동 방향을 계산하여 입장 또는 퇴장 이벤트를 판단합니다.
    - 문 제어 로직을 적용하여 문을 열거나 닫습니다.
    - 상태 변수를 업데이트하여 시스템의 현재 상태를 유지합니다.
3. 버튼 입력 처리:
    - 사용자가 내부에서 버튼을 눌렀을 때 콜백 함수를 통해 문을 제어하고 상태 변수를 업데이트합니다.
4. 종료 처리:
    - 프로그램이 종료되면 카메라와 GPIO 설정을 정리하고, 필요한 경우 로그를 기록합니다.
    
# 7.동일 인물 판단 방법
## 7.1 객체 추적 알고리즘 적용
- 추적기 초기화 및 업데이트
## 7.2 문 제어 로직에 적용
- 입장 및 퇴장 이벤트 처리

# 8. 문 제어 로직 구현
## 8.1 상태 관리 변수
- **``is_occupied``변수**
    - 화장실 점유 상태 저장 (true or false)
- **``tracking``변수**
    - 객체 추적 상태를 저장
- **``prev_position``변수**
    - 이전 프레임에서의 객체 위치 저장

## 8.2 문 제어 로직 정리
- **휠체어 감지시**
    - ``is_occupied``가 False이면 문열기
- **입장 이벤트 발생 시**
    - ``is_occupied``를 True로 설정하고 문 닫기
- **퇴장 이벤트 발생 시**
    - ``is_occupied``를 False로 설정하고 문 열기
- **사용자 버튼 입력 처리**
    - 내부 닫힘 버튼:``is_occupied``를 True로 설정하고 문 닫기
    - 내부 열림 버튼:``is_occupied``를 False로 설정하고 문 열기

# 9. 소프트웨어 구현 세부사항
## 9.1 멀티스레딩 적용(필요 시)
- 추론 및 영상 처리 스레드
- GPIO 이벤트 처리 스레드
- 스레드 종료 처리
## 9.2 예외 처리 및 안전성 개선
- 예외 및 종료 시 리소스 해제
- 로그 시스템 구축

# 10. 테스트 및 디버깅

## 10.1 시나리오별 테스트
- **단일 사용자 입장 및 퇴장**
- **다수 사용자 연속 입장**
- **비휠체어 사용자 접근 시 동작 확인**
- **버튼 고장 등 비상 상황 대응 확인**

## 10.2 성능 측정
- **추론 속도(FPS)확인**
- **감지 정확도 평가(오탐지 및 미탐지 분석)**

## 10.3 문제 해결
- **환경 요인 조정**
    - 조명 조건, 카메라 위치 등 조정
- **모델 재학습**
    - 추가 데이터로 모델 개선 및 재학습

# 11. 보안 및 프라이버시 고려사항
## 11.1 개인 정보 보호
- **데이터 저장 최소화**
    - 영상 데이터나 개인 식별 정보 저장하지 않음
- **실시간 처리**
    - 모든 영상 처리는 메모리 내에서 실시간으로 수행

## 11.2 시스템 접근 보안
- **물리적 보안**
    - 장비를 잠금함 등에 보관하여 무단 접근 방지
- **시스템 설정 보호**
    - 설정 변경 시 비밀번호 등 인증 절차 적용

# 12. 최적화 및 유지보수
## 12.1 시스템 모니터링
- **상태 정보 표시**
    -LED나 LCD를 통해 시스템 상태 및 동작 표시
- **로그 저장(옵션)**
    -동작 이력 및 오류 로그를 로컬에 저장하여 문제 발생 시 참고

## 12.2 정기적인 유지보수
- **하드웨어 점검**
    - 카메라, 버튼, 릴레이 등 하드웨어의 정상 동작 확인
- **소프트웨어 업데이트**
    - 최신 보안 패치 및 기능 개선 사항 반영

## 12.3 사용자 피드백 수집
- **문제 보고 체계 구축**
    - 사용자가 문제를 쉽게 보고할 수 있도록 연락처나 QR코드 제공
- **피드백 반영**
    - 사용자 의견 수렴하여 시스템 개선에 활용
